{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict if a mail is a spam or not.\n",
    "\n",
    "Fit and transform the training data X_train using a Count Vectorizer ignoring terms that have a document frequency strictly lower than 5 and using character n-grams from n=2 to n=5.\n",
    "\n",
    "Use this document-term matrix and the following additional features:\n",
    "- the length of document (number of characters)\n",
    "- number of digits per document\n",
    "- number of non-word characters (anything other than a letter, digit or underscore.)\n",
    "- fit a Logistic Regression model with regularization C=100. Then compute the area under the curve (AUC) score using the transformed test data.\n",
    "\n",
    "Also find the 10 smallest and 10 largest feature from the model and return them along with the AUC score in a tuple.\n",
    "\n",
    "The list of 10 smallest coefficients should be sorted smallest first, the list of 10 largest coefficients should be sorted largest first.\n",
    "\n",
    "The three features that were added to the document term matrix should have the following names should they appear in the list of coefficients: ['length_of_doc', 'digit_count', 'non_word_char_count']\n",
    "\n",
    "This function should return a tuple (AUC score as a float, smallest coefs list, largest coefs list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Go until jurong point, crazy.. Available only ...       0\n",
       "1                      Ok lar... Joking wif u oni...       0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3  U dun say so early hor... U c already then say...       0\n",
       "4  Nah I don't think he goes to usf, he lives aro...       0\n",
       "5  FreeMsg Hey there darling it's been 3 week's n...       1\n",
       "6  Even my brother is not like to speak with me. ...       0\n",
       "7  As per your request 'Melle Melle (Oru Minnamin...       0\n",
       "8  WINNER!! As a valued network customer you have...       1\n",
       "9  Had your mobile 11 months or more? U R entitle...       1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "spam_data = pd.read_csv('spam.csv')\n",
    "spam_data['target'] = np.where(spam_data['target']=='spam',1,0)\n",
    "spam_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], \n",
    "                                                    spam_data['target'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor():\n",
    "    vect = CountVectorizer(min_df=5, ngram_range=(2,5), analyzer='char_wb').fit(X_train)\n",
    "    \n",
    "    # transform texts into a document-term matrix\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    X_test_vectorized = vect.transform(X_test)\n",
    "    \n",
    "    # get the len of each X_train as a feature\n",
    "    X_train_len = [len(x) for x in X_train]\n",
    "    X_test_len = [len(x) for x in X_test]\n",
    "    \n",
    "    # get the number of digits for of each document\n",
    "    X_train_n_digit = [len(re.findall('\\d', x)) for x in X_train]\n",
    "    X_test_n_digit = [len(re.findall('\\d', x)) for x in X_test]\n",
    "    \n",
    "    # get the number of non word chars for of each document\n",
    "    X_train_n_nwords = [len(re.findall('\\W', x)) for x in X_train]\n",
    "    X_test_n_nword = [len(re.findall('\\W', x)) for x in X_test]\n",
    "\n",
    "    # Enrich the train and test data with the new feature\n",
    "    X_train_enriched = add_feature(X_train_vectorized, X_train_len)\n",
    "    X_train_enriched = add_feature(X_train_enriched, X_train_n_digit)\n",
    "    X_train_enriched = add_feature(X_train_enriched, X_train_n_nwords)\n",
    "\n",
    "    X_test_enriched = add_feature(X_test_vectorized, X_test_len)\n",
    "    X_test_enriched = add_feature(X_test_enriched, X_test_n_digit)\n",
    "    X_test_enriched = add_feature(X_test_enriched, X_test_n_nword)\n",
    "    \n",
    "    # Train a Logistic model\n",
    "    model = LogisticRegression(max_iter=100)\n",
    "    model.fit(X_train_enriched, y_train)\n",
    "\n",
    "    # Predict test documents\n",
    "    predictions = model.predict(X_test_enriched)\n",
    "    \n",
    "    feature_names = vect.get_feature_names() + ['length_of_doc', 'digit_count', 'non_word_char_count']\n",
    "    s1 = pd.Series(model.coef_[0], index=feature_names)\n",
    "    \n",
    "    return roc_auc_score(y_test, predictions), s1.nsmallest(10).index.tolist(), s1.nlargest(10).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.9759031798040846\n",
      "Top ten smallest feature: [' i', 'ca', '..', '. ', ' m', 'pe', ' go', 'if', 'us', ' h']\n",
      "Top ten largest feature: ['digit_count', 'xt', 'co', ' r', 'ne', 'ia', ' ba', ' x', 'ian ', 'ba']\n"
     ]
    }
   ],
   "source": [
    "result = predictor()\n",
    "print(\"AUC score: {}\\nTop ten smallest feature: {}\\nTop ten largest feature: {}\".format(result[0], result[1], result[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
